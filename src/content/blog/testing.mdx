---
title: "Testing"
description: "And become a better engineer"
pubDate: "Mar 21 2024"
headerColor: "#7fd8be"
contrastColor: "#f48498"
heroImage: "/blog/testing/header-icon.svg"
---

import Cookie from '../../components/Cookie.astro'

Although there are [many forms of testing](https://medium.com/codex/types-of-testing-de4cdd98df77), in this article I will focus on unit testing. I believe they are the easiest to setup, easy to write/maintain and when done properly [end-to-end testing may become obsolete](https://www.youtube.com/watch?v=QFCHSEHgqFE).

---

> Engineers conduct tests and experiments to evaluate the performance, safety, and reliability of products or systems. This may involve using specialized equipment, conducting simulations, or performing real-world trials.
>
> <cite>[ChatGPT](https://chat.openai.com/share/97ddf631-1171-4c18-9f70-40e2b6f30e8b)</cite>

## The software engineer

In the physical world you rely on engineers to be due diligence in their work. You wouldn't like to have a bridge collapse because it was not tested properly, right?

So how is it that I come across many _software engineers_ that do not test their code?

It is our job that the code we write works as intended, and -preferably- keeps on working as intended after changes have been made.

This is, to me, part of the _engineering_ mindset.

### Some ðŸš©ðŸš©ðŸš©ðŸš©

Every project (-team) is different, but there are some common pitfalls that I have seen over and over again which should raise some red flags to you.

#### ðŸš© No tests runner has been setup

This one is kind of obvious, but when a project has no test runner setup it does not motivate (new) team members to write tests.

Why would you bother writing tests as this project cleary does not find them important?

This is true for a local setup which enables developers to validate their code locally. But it is equaly important to have a test runner in your CI/CD pipeline.

```yml
# Simple github-actions example
name: Node.js CI

on:
  pull_request:
    branches: [main] # Can extend to other branches

jobs:
  is-code-okay:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Use Node.js 18
        uses: actions/setup-node@v2
        with:
          node-version: 18
      - run: npm ci
      - run: npm run test
```

This way you can ensure no old code is broken unintentionally. Even when you forget about running the tests locally.

#### ðŸš© Tests are treated as second class citizens

When tests are stored away in a seperate a folder it makes them harder to find and easier to forget about.

There is no constant nudge to write tests.

```
project-root/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.ts
â”‚   â””â”€â”€ utils.ts
â”‚
â””â”€â”€ test/
    â”œâ”€â”€ app.test.ts
    â””â”€â”€ utils.test.ts
```

Try placing the tests as part of the source code, next to the code they are testing.

This way the project itself tells you _"we care about tests"_ just by working on it.

```
project-root/
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ app.ts
    â”œâ”€â”€ app.test.ts
    â”œâ”€â”€ utils.ts
    â””â”€â”€ utils.test.ts
```

#### ðŸš© Test code is not <em class="ml-2">clean</em>

Why do you go to great lengths to write clean, maintainable code, but throw all of this out of the window when writing tests?

Test code should adhere to the same standards of quality as the code it is testing.

> Indeed, the ratio of time spent reading versus writing is well over 10 to 1. We are constantly reading old code as part of the effort to write new code. ...[Therefore,] making it easy to read makes it easier to write.
>
> <cite>Clean Code: A Handbook of Agile Software Craftsmanship</cite>

> Any fool can write code that a computer can understand. Good programmers write code that humans can understand.
>
> <cite>Refactoring: Improving the Design of Existing Code</cite>

---

Some indicators I have found that you throw out clean code principles when writing tests:

---

1. Ignoring test files in your linting

Sure, this makes your life easier in the short term. But over the life-span of a project you will end up with a lot of unmaintainable tests (read technical debt) you have created yourself unnecessarily.

```typescript
{
    "ignorePatterns": ["**/*.test.ts"],
}
```

2. Making the test (file) a puzzle by itself

Tests can be considered documentation itself when written properly.

Why make it harder for the next person, which is most likey going to be you, to understand what is going on?

```typescript
it("should do the thing", () => {
  const a = [1, 10];
  const b = [2, 50];

  // @ts-ignore
  const d = calculateDistance(a, b);
  const c = plotCurve(d, {} as unknown as MyOptions);

  expect(c).toBe([
    [1, 20],
    [7, 18],
    [3, 49],
  ]);
});
```

Act like you are writing _"normal"_ code.

This makes it easier to skim over the tests to see what is being tested and what the expected outcome is.

A good pattern to follow is the [_Arrange, Act, Assert_](https://automationpanda.com/2020/07/07/arrange-act-assert-a-pattern-for-writing-good-tests/) pattern.

```typescript
it("should plot a curce between two data points", () => {
  // Arrange
  const pointA = [1, 10];
  const pointB = [2, 50];
  const expectedCurve = [
    [1, 20],
    [7, 18],
    [3, 49],
  ];

  // Act
  const distance = calculateDistance(pointA, pointB, true);
  const result = plotCurve(distance, { step: 3 });

  // Assert
  expect(result).toEqual(expectedCurve);
});
```

3. The test has too many responsibilities

When a test is _doing_ too many things at once it becomes harder to pinpoint what is going wrong when the tests start failing.

```typescript
it("should test everything", () => {
  // Should set global `someGlobalValue` to `true`
  const result = doSomething("foo", process.env.BAR); // Relies on local DB

  expect(result).toBe(false);
  expect(myMethod).toHaveBeenCalledWith({ foo: "foo", bar: "bar" });
  expect(myOtherMethod).not.toHaveBeenCalled();
});

it("should test some other thing", () => {
  // Only works when the previous test has been run
  const result = doSomeOtherThing(someGlobalValue, 5);

  expect(result).toBe("foo");
});
```

Tests should be

- a) **independant** - `it("should not rely on the outcome of another test")`
- b) **repeatable** - `it("should be runnable in any environment")`
- c) **self-validating** - `it("should return a clear pass or fail result")`

```typescript
jest.mock("myLocalDbAdapter"); // Make sure the tests can run anywhere

describe(doSomething.name, () => {
  it.each`
    input1   | input2   | expected
    ${"foo"} | ${"bar"} | ${false}
    ${"bar"} | ${"foo"} | ${true}
  `(
    "Returns $expected for $input1 and $input2",
    ({ input1, input2, expected }) => {
      const result = doSomething(input1, input2);

      expect(result).toBe(expected);
    }
  );

  it(`does should call ${myMethod.name}`, () => {
    doSomething("foo", "bar");

    expect(myMethod).toHaveBeenCalledWith({ foo: "foo", bar: "bar" });
  });

  it(`does not call ${myOtherMethod.name} when passing "foo" and "bar"`, () => {
    doSomething("foo", "bar");

    expect(myOtherMethod).not.toHaveBeenCalled();
  });

  it(`does call ${myOtherMethod.name} when passing "bar" and "foo"`, () => {
    doSomething("bar", "foo");

    expect(myOtherMethod).toHaveBeenCalledTimes(1);
  });
});

describe(doSomeOtherThing.name, () => {
  it.each`
    someGlobalValue | expected
    ${true}         | ${"foo"}
    ${false}        | ${"bar"}
  `(
    "Returns '$expected' when `someGlobalValue` is $someGlobalValue",
    ({ expected, $someGlobalValue }) => {
      // No more coupling on the outcome of the previous test
      jest.spyOn(global, "someGlobalValue").mockReturnValue(someGlobalValue);

      const result = doSomeOtherThing(someGlobalValue, 5);

      expect(result).toBe(expected);
    }
  );
});
```

Yes, the test file is significantly longer than the original example. But it is easier to follow the intents of each test. And as a bonus, when a test fails you can pinpoint the issue much faster.

#### ðŸš© Coverage !== Confidence

Hitting a certain percentage of coverage does not mean your software is properly tested.

The following code has a **80% coverage**, as this seems to be the general (mandatory) coverage goal.

```typescript
// src/test-me.ts
import { deleteImportantData } from "./utils";

class TestMe {
  private shouldDeleteData: boolean = false;

  constructor(
    public readonly foo: number,
    public readonly bar: string,
    public readonly baz: boolean
  ) {
    if (foo > 10) {
      this.shouldDeleteData = true;
    }
  }

  public importantMethodToTest(): void {
    if (this.shouldDeleteData) {
      deleteImportantData();
    }
  }
}

// src/test-me.test.ts
import { TestMe } from "./test-me";

describe(TestMe.name, () => {
  it("initializes properly", () => {
    const testMe = new TestMe(11, "bar", true);

    expect(testMe.foo).toBe(11);
    expect(testMe.bar).toBe("bar");
    expect(testMe.baz).toBe(true);
  });
});
```

But what are you actually testing here? If the JavaScript constructor still works?

Let's have a look at the next example:

```typescript
// src/add.ts
function add(array: number[]) => {
  return array[0] + array[1];
}

// src/add.test.ts
describe(add.name, () => {
  it("should add two numbers", () => {
    const result = add([1, 2]);

    expect(result).toBe(3);
  });
});
```

And boom, you have **100% coverage**! But you are missing out on testing the edge cases. What if the array is empty? What if the array only has one element?

Setting a (mandatory) coverage percentage is a ~stupid~ bad idea. More often than not this will lead to poorer tests just for the sake of increasing the coverage.

I would not go as far as to [not write any unit tests](https://www.youtube.com/watch?v=ZGKGb109-I4) though, just be [thoughtful on _what_ you are testing](https://www.youtube.com/watch?v=IInciWyU74U).

---

Wow, you made it this far, have a <Cookie name="testing" /> before I continue with more practical tips.

---

## Using specialized equipment

Being new in testing, or development for that matter, can be overwhelming. And although you can [generate your tests with AI ](https://www.jetbrains.com/help/idea/generate-tests.html). I think there are other tools out there which enable you to write better tests youself.

The list below is not exhaustive, but they will give you a good starting point.

### Build for speed

Time moves on, and so do our tools.

Most of us do not use [`chai`](https://www.chaijs.com) or [`mocha`](https://mochajs.org/) anymore to write and run our tests. It is quite common to see [`jest`](https://jestjs.io/) being the work-horse nowadays.

> Test should be fast. They should run quickly. When tests run slow, you won't want to run them frequently. If you don't run them frequently, you won't find problems early enough to fix them easily. You won't feel as free to clean up the code. Eventually the code will begin to rot.
>
> <cite>Clean Code: A Handbook of Agile Software Craftsmanship</cite>

[Vitest](https://vitest.dev) is a drop-in replacement for Jest all while being faster.

### Validation

A common way your code can break is when the data you receive is not what you expect. You should treat all external data as untrusted.

Given the following example

```typescript
fetch("https://api.example.com")
  .then((response) => response.json())
  .then((data) => {
    if (!data.property) {
      throw new Error("Property is missing");
    }

    if (typeof data.anotherThing !== "number") {
      throw new Error("Another thing is not a number");
    }

    // ... etc

    return data as MyType;
  })
  .catch((error) => {
    // Error handling
  });
```

You can write a lot safe-guards and unit tests to validate the data you receive is of `MyType` and otherwise it should throw an error.

```typescript
describe("fetchData", () => {
  it("should throw and error when `property` is missing", async () => {
    jest.spyOn(global, "fetch").mockResolvedValue({
      json: () => Promise.resolve({}),
    });

    expect(fetchData()).rejects.toThrow("Property is missing");
  });

  it("should throw an error when `anotherThing` is not a number", () => {
    jest.spyOn(global, "fetch").mockResolvedValue({
      json: () => Promise.resolve({ property: "foo", anotherThing: "bar" }),
    });

    expect(fetchData()).rejects.toThrow("Another thing is not a number");
  });

  // ... etc
});
```

But instead you can use a schema validator like [`zod`](https://zod.dev) or [yup](https://github.com/jquense/yup) to parse and validate the data you receive.

```typescript
import { z } from "zod";

const MyType = z.object({
  property: z.string(),
  anotherThing: z.number(),
});

fetch("https://api.example.com")
  .then((response) => response.json())
  .then((data) => MyType.parse(data))
  .catch((error) => {
    // Error handling
  });
```

This will save a lot of effort in validating the data itself and, in my opinion, does not require any unit tests besides the error handling anymore.

### Passing objects

Writing clean tests can become tedious when you have to pass a whole object while your tests only needs one on the properties.

What is see happening a lot is the following:

```typescript
describe("Annoying boilerplate", () => {
  it("can type-cast to make the test work", () => {
    const result = testMe({
      property: "foo",
    } as any as MyType);

    expect(result).toBe(true);
  });

  it("can @ts-ignore to make the test work", () => {
    // @ts-ignore
    const result = testMe({
      property: "foo",
    });

    expect(result).toBe(true);
  });

  it("Can put the whole object to make the test work", () => {
    const result = testMe({
      property: "foo", // Test only requires this property-
      nestedProperty: {
        anotherProperty: "bar",
      },
    });

    expect(result).toBe(true);
  });
});
```

A sollution I used before was to make use of the [builder pattern](https://refactoring.guru/design-patterns/builder) to generate the objects for the tests.

```typescript
class MyTestBuilder {
  private property: string = "foo";
  private nestedProperty: { anotherProperty: string } = {
    anotherProperty: "bar",
  };

  public withProperty(property: string): MyTestBuilder {
    this.property = property;
    return this;
  }

  public withNestedProperty(nestedProperty: { anotherProperty: string }) {
    this.nestedProperty = nestedProperty;
    return this;
  }

  public build(): MyType {
    return {
      property: this.property,
      nestedProperty: this.nestedProperty,
    };
  }
}
```

This allows you to create a `MyType` object with default values and override them when needed. This can be used in the following way:

```typescript
describe("Building your tests", () => {
  it("can pass the default values", () => {
    const result = testMe(new MyTestBuilder().build());

    expect(result).toBe(true);
  });

  it("can set specific properties for your test", () => {
    const result = testMe(new MyTestBuilder().withProperty("bar").build());

    expect(result).toBe(false);
  });

  it("can set multuple properties", () => {
    const result = testMe(
      new MyTestBuilder()
        .withProperty("bar")
        .withNestedProperty({ anotherProperty: "foo" })
        .build()
    );

    expect(result).toBe(false);
  });
});
```

But sometimes you just need _to force something into a space_. [`@total-typescript/shoehorn`](https://www.npmjs.com/package/@total-typescript/shoehorn) is the tool you are looking for. It will allow you to pass partial data in tests while keeping TypeScript happy.

```typescript
import { fromPartial } from "@total-typescript/shoehorn";

describe("No more boilerplate", () => {
  it("can pass partial data", () => {
    const result = new MyTest(fromPartial({ property: "foo" }));

    expect(result).toBe(true);
  });
});
```

This removes all the boilerplate code and allows you to focus on the actual test.

### UI testing

As you are working with Typescript, there is a big change you will need to test some frontend code as well.

You might be familiar with tools such as [`storybook`](https://storybook.js.org/docs/writing-tests/test-runner), [`cypress`](https://www.cypress.io) or [`playwright`](https://playwright.dev).

These tools are powerfull in their own right, but I think they are _bloatware_ when writing unit tests.

[`@testing-library`](https://testing-library.com) are _"simple and complete testing utilities that encourage good testing practices"_ which allows you to test the your DOM.

### Code coverage

Altough I am [against setting coverage targets](#-coverage--confidence), it is valuable to know what parts of your code are tested and which are not.

[Codecov](https://about.codecov.io) or [Sonarqube](https://www.sonarsource.com/products/sonarqube/) can give you these insights. You can use it to make educated decisions on the state of your codebase and determine where to focus your testing efforts.

## Conducting simulations

The beaty of testing is that you can _mock_ (simulate) almost everything. This allows you to put your system under stress and force it into states that are hard(er) to reproduce in real life.

```typescript
const fetchData = async (triesLeft = 1) => {
  try {
    const response = await fetch("https://api.example.com");
    const data = await response.json();
    const parsed = MyType.parse(data);

    saveMyData(parsed);
  } catch (error) {
    if (triesLeft > 0) {
      return fetchData(triesLeft - 1);
    }
    // Error handling
  }
};

describe("simulate your software", () => {
  it("can throw errors", async () => {
    jest.spyOn(global, "fetch").mockRejectedValue(new Error("Network error"));

    await fetchData(0);

    expect(saveMyData).not.toHaveBeenCalled();
  });

  it("can pass unexpected inputs", async () => {
    jest.spyOn(global, "fetch").mockResolvedValue({
      json: () => Promise.resolve({ foo: "bar", bar: "baz" }),
    });

    await fetchData(0);

    expect(saveMyData).not.toHaveBeenCalled();
  });

  it("can validate retry mechanisms", async () => {
    jest
      .spyOn(global, "fetch")
      .mockResolvedValueOnce({
        json: () => throw new Error("Network error"),
      })
      .mockResolvedValue ({
        json: () => Promise.resolve({ foo: "bar", bar: 42 }),
      });

    await fetchData(1);

    expect(saveData).toHaveBeenCalledWith({ foo: "bar", bar: 42 });
  });
});
```

You can go even deeper by [mocking any interface or object ](https://www.npmjs.com/package/vitest-mock-extended) to give you full control over the simulation.

## Performing real-world trials

Testing is great, but you are conducting unit test they are placed in a vacuum.

Software does not exist in a vacuum, and things **will** break.

> When you get a bug report, start by writing a unit test that exposes the bug.
>
> <cite>Refactoring: Improving the Design of Existing Code</cite>
