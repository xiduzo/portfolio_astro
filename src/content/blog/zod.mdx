---
title: "Zod"
description: "Stronger interfaces, cleaner code, fewer bugs"
pubDate: "May 15 2024"
headerColor: "#3068B7"
contrastColor: "#41B983"
heroImage: "/blog/zod/header-icon.svg"
shareImage: "/blog/zod/bridge.png"
---

import Cookie from '../../components/Cookie.astro'

I am a big fan of TypeScript, but one thing that is lacking compared to _real_ strongly type languages: the runtime validation of the data.

While our static type checker has validated everything _works_, eventually we have to interact with the scary outside world.

This can be user input, a response from an API, streamed data, reading data from disk or even loading environment variables.

## Lying interfaces

One thing that is more harmful than no interface, is a lying interface. This will set you --and your team-- up for a world of unnecessary debug sessions.

---

Let's say you have a neat generic function that fetches data from an API:

```typescript
async function fetchData<T>(url: string): Promise<T> {
  const response = await fetch(url);
  return response as T;
}
```

You have properly declared an interface for the data you expect:

```typescript
interface ApiData {
  foo: string;
  bar: number;
}
```

And when you call the function you expect to get the data you want:

```typescript
const response = await fetchData<ApiData>("example.api.org");
//    ^? `ApiData`
```

At first glance the interface looks fine, the function has explicit type inputs and outputs.

But there are at least 2 lies with this inferface:

1. The return type is a lie. The function can return anything, not just `ApiData`.
2. The function can throw an error, but you don't know that from the interface.

You can easily spot those lies in source code whenever you see an `as MY_LAZY_LIE`.

---

We can fix the interface by adding a runtime validation library like [Zod](https://zod.dev/)[^1]. This will require some initial extra typing.

[^1]: Zod is my personal favourite runtime validation library for JavaScript. It has a very clean API and is very powerful. But be aware that there is [more](https://zod.dev/?id=comparison) out there.

Instead of an IDE which is constantly lying to you, you will gain some new type-safe superpowers.

```typescript
import { SafeParseReturnType } from "zod";

type Response<T extends ZodSchema> =
  | SafeParseReturnType<T, z.output<T>>
  | { success: false; error: unknown };

async function fetchData<T extends ZodSchema>(
  url: string,
  schema: T
): Promise<Response<T>> {
  try {
    const response = await fetch(url);
    return schema.safeParse(response);
  } catch (error) {
    return { success: false, error };
  }
}
```

Instead of defining an interface, we define a schema with `Zod` and infer the interface from it.

```typescript
import { z } from "zod";

const apiData = z.object({
  foo: z.string(),
  bar: z.number(),
});

// Not required for this example but below is a
// direct replacement for the previous interface.
type ApiData = z.infer<typeof apiData>;
```

Now when you call the function you are sure that the data you get is according to the schema. And if not you get proper typed errors.

```typescript
const response = await fetchData("example.api.org", apiData);

if (response.success) {
  console.log(response.error);
  //                   ^? `undefined`
  console.log(response.data);
  //                   ^? `ApiData`
} else {
  console.log(response.data);
  //                   ^? `undefined`
  if (response.error instanceof ZodError) {
    // The data we got from the API is not according to the schema
    console.log(response.error);
    //                   ^? `ZodError`
    return;
  }

  // The API request failed
  console.log(response.error);
  //                   ^? `unknown`
}
```

## Back to the real world

For a client, [Growy](https://www.growy.nl/), I was working on recently most of the data was coming from unstructured data sources.

Growy is highly automizing vertical farming and is relying on a lot of IoT devices which are sending and receiving data to and from the cloud.

In the software the data comes from two sources: DynamoDB and MQTT messages. In order to work with this unstructured data the project had classes which allowed for creation of data object for static type-safety.

```typescript
export class ExampleFromProject {
  id: string;
  type: string;
  amount: number;

  constructor(id: string, type: string, amount: number) {
    this.id = id;
    this.type = type;
    this.amount = amount;
  }

  static fromDynamoRecord(data: Record<string, string | number | undefined | null>) {
    return new ExampleFromProject(
      data.id as string,
      data.type as string,
      data.amount as number
    );
  }

  // ... other methods
}
```

For DynamoDD queries we had functions similar to:

``` typescript
function getRecord(id: string) {
  const { Item } = await dynamoClient.send(<QUERY>);
  //      ^? `Record<string, any>`

  return ExampleFromProject.fromDynamoRecord(Item);
}
```

For MQTT messages we made handlers which parsed data as follows:

```typescript
mqqClient.onMessage(message => {
  const data = JSON.parse(message.payload.toString());
  //    ^? `any`

  const example = new ExampleFromProject(data.id, data.type, data.amount);

  // ... do something with the data
})
```

But as you might have noticed, we have some little `as LAZY_LIE`s in the code.

When parsing a record from the DynomoDB we are assuming that the data is always there and of the correct type.

When parsing a message from MQTT we are assuming that the message payload is always a stringified JSON object **and** contains the correct data.

All interfaces, and static types are correct, the runtime data could still be (and sometimes was) wrong.

---

While most of the systems worked fine, the platform was only tested in a controlled environment with simulated devices.

When we started to get actual data from the real world (read IoT devices) bugs started to surface. And they started to appear more frequently then with the simulated data.

Some bugs were found immediately, as the services started breaking down when the wrong data was received:

`TypeError: Cannot read property 'foo' of undefined` or `NaN` values after calculations were not uncommon.

But some bugs were more subtle, wrongly received data was stored in the DynamoDB table and only processed in later stages. This made the root cause of the bug harder to find.

### Adding runtime validation

In order to prevent services from crashing and data from being stored incorrectly, we added zod validation to the data objects.

Because the project was already quite large when I joined, had a very heavy OOP style, and the data objects were used in many places, we decided to not go full-in on _the zod way_.

Instead, we added zod parsing capabilities to the existing classes. This involved some Typescript magic, but made the transition much easier.

---

The following code took some time to made, had its' fair share of issues while developing and also gave me headaches. Have a <Cookie name="zod" /> before you continue.

All our classes would extend the following `Parsable` class:

```typescript
import { SafeParseReturnType, ZodSchema, ZodTypeDef } from 'zod'

export interface GeneratedParsable<Output = unknown, TypeDef extends ZodTypeDef = ZodTypeDef, Input = Output> {
  schema: ZodSchema<Output, TypeDef, Input>
  // passing `unknown` instead of `any` will beak TS
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  parse<TFinal extends new (data: any) => InstanceType<TFinal>>(this: TFinal, value: unknown): InstanceType<TFinal>
  // passing `unknown` instead of `any` will beak TS
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  safeParse(data: unknown): SafeParseReturnType<Input, Output>
  new (input: Input): Output
}

export function Parsable<Output = unknown, TypeDef extends ZodTypeDef = ZodTypeDef, Input = Output>(schema: ZodSchema<Output, TypeDef, Input>) {
  const Generated = class {
    static schema = schema
    static parse<T extends typeof Generated>(this: T, data: unknown) {
      return new this(data as Input)
    }
    static safeParse(data: unknown) {
      const result = schema.safeParse(data)

      if (!result.success) {
        console.warn('Failed to parse data', { data, error: result.error })
      }

      return result
    }

    constructor(input: Input) {
      const result = Generated.safeParse(input)

      if (!result.success) {
        throw result.error
      }

      Object.assign(this, result.data)
    }
  }

  return Generated as unknown as GeneratedParsable<Output, TypeDef, Input>
}
```

We can extend the `Parsable` in our data objects to give it runtime validation capabilities.

```typescript
import { z } from 'zod'

const schema = z.object({
  id: z.string(),
  type: z.string(),
  amount: z.number()
})

export class ExampleFromProject extends Parsable(schema) {
  // ... existing code
}
```

We can now use the `parse` and `safeParse` methods to validate any unknown data.

```typescript
const input = { id: '123', type: 'foo', amount: 42 }

const example = ExampleFromProject.parse(input)
// or
const { success, data, error } = ExampleFromProject.safeParse(input)
```

From this moment onwards we can be sure the data we are working with is in the expected format, no more need for `as LAZY_LIE`s.

And on receiving faulty data, we can pin-point it better and (hopfully) handle it gracefully.


### The aftermath

After rolling out the changes a lot of services started reporting faulty data inputs. Initially, the team was not very pleased with the constant need for fixing _unnecessary errors_. Instead of adding new features the focus was on data integrity for nearly a full month.

But as time went on, received data was more and more in line with the expected format. The team started to see the benefits of the changes, especially when new IoT devices came online which were still sending old data.

The services are more stable, and the data is more reliable.
